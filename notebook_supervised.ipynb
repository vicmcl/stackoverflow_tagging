{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "XSttyWoSnupl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.flush_and_unmount()\n",
        "drive.mount(str(drive_path))"
      ],
      "metadata": {
        "id": "v-ypNnxbnwWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "KGvAVReB2p79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend, metrics\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gInhw-hW2phw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(drive_path / \"My Drive\" / \"OCR\" / \"5_StackOverflow\" / \"preprocessed_questions.json\")"
      ],
      "metadata": {
        "id": "_XvGWoWt2_Vz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_size=300\n",
        "w2v_window=5\n",
        "w2v_min_count=1\n",
        "w2v_epochs=100\n",
        "sentences = df['sentence_bow_lem'].str.split().tolist()\n",
        "maxlen = max(len(s) for s in sentences)"
      ],
      "metadata": {
        "id": "HLOOsB6528pc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = gensim.models.Word2Vec(\n",
        "    min_count=w2v_min_count, window=w2v_window,\n",
        "    vector_size=w2v_size,\n",
        "    seed=42,\n",
        "    workers=1\n",
        ")\n",
        "\n",
        "w2v_model.build_vocab(sentences)\n",
        "\n",
        "w2v_model.train(\n",
        "    sentences,\n",
        "    total_examples=w2v_model.corpus_count,\n",
        "    epochs=w2v_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "1FcXOHsF3e7T",
        "outputId": "d100ced8-998e-4b9c-b28b-a14e1a0116b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351174, 468100)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_vectors = w2v_model.wv\n",
        "w2v_words = model_vectors.index_to_key"
      ],
      "metadata": {
        "id": "QhEzrOol3tRp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "x_sentences = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(sentences),\n",
        "    maxlen=maxlen,\n",
        "    padding='post'\n",
        ")"
      ],
      "metadata": {
        "id": "AEMWadFR3u-B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
        "\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "    if model_vectors[word] is not None:\n",
        "        embedding_matrix[idx] = model_vectors[word]"
      ],
      "metadata": {
        "id": "B6by3UdR32l5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(len(x_sentences),maxlen),dtype='float64')\n",
        "\n",
        "word_input = Input(shape=(maxlen,),dtype='float64')\n",
        "\n",
        "word_embedding = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=w2v_size,\n",
        "    weights = [embedding_matrix],\n",
        "    input_length=maxlen\n",
        ")(word_input)\n",
        "\n",
        "word_vec = GlobalAveragePooling1D()(word_embedding)\n",
        "\n",
        "embed_model = Model([word_input],word_vec)\n",
        "\n",
        "embed_model.summary()"
      ],
      "metadata": {
        "id": "PZZd_C7j4LzG",
        "outputId": "1af1490d-205a-4ee9-bac5-a2480f45118c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 14)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 14, 300)           315300    \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 300)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315300 (1.20 MB)\n",
            "Trainable params: 315300 (1.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embed_model.predict(x_sentences)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "xHlrEWvA4oPI",
        "outputId": "bcc8cfc9-0d64-4238-eec8-4d6075a748a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpLhUjLxnieu"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiwAWO7sniew"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import metrics as kmetrics\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Bert\n",
        "import os\n",
        "import transformers\n",
        "from transformers import *\n",
        "\n",
        "os.environ[\"TF_KERAS\"]='1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uHEPl7Zniey"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)\n",
        "print(tensorflow.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(tf.test.is_built_with_cuda())"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}