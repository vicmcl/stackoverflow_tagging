{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "XSttyWoSnupl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.flush_and_unmount()\n",
        "drive.mount(str(drive_path))"
      ],
      "metadata": {
        "id": "v-ypNnxbnwWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(drive_path / \"My Drive\" / \"OCR\" / \"5_StackOverflow\" / \"preprocessed_questions.json\")"
      ],
      "metadata": {
        "id": "DeAZZZdH5ahu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "KGvAVReB2p79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import gensim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gInhw-hW2phw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_size=300\n",
        "w2v_window=5\n",
        "w2v_min_count=1\n",
        "w2v_epochs=100\n",
        "sentences = df['sentence_bow_lem'].str.split().tolist()\n",
        "maxlen = max(len(s) for s in sentences)"
      ],
      "metadata": {
        "id": "HLOOsB6528pc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = gensim.models.Word2Vec(\n",
        "    min_count=w2v_min_count,\n",
        "    window=w2v_window,\n",
        "    vector_size=w2v_size,\n",
        "    seed=42,\n",
        "    workers=1\n",
        ")\n",
        "\n",
        "w2v_model.build_vocab(sentences)\n",
        "\n",
        "w2v_model.train(\n",
        "    sentences,\n",
        "    total_examples=w2v_model.corpus_count,\n",
        "    epochs=w2v_epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FcXOHsF3e7T",
        "outputId": "d100ced8-998e-4b9c-b28b-a14e1a0116b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351174, 468100)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_vectors = w2v_model.wv\n",
        "w2v_words = model_vectors.index_to_key"
      ],
      "metadata": {
        "id": "QhEzrOol3tRp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "x_sentences = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(sentences),\n",
        "    maxlen=maxlen,\n",
        "    padding='post'\n",
        ")"
      ],
      "metadata": {
        "id": "AEMWadFR3u-B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
        "\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "    if model_vectors[word] is not None:\n",
        "        embedding_matrix[idx] = model_vectors[word]"
      ],
      "metadata": {
        "id": "B6by3UdR32l5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(len(x_sentences),maxlen),dtype='float64')\n",
        "\n",
        "word_input = Input(shape=(maxlen,),dtype='float64')\n",
        "\n",
        "word_embedding = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=w2v_size,\n",
        "    weights = [embedding_matrix],\n",
        "    input_length=maxlen\n",
        ")(word_input)\n",
        "\n",
        "word_vec = GlobalAveragePooling1D()(word_embedding)\n",
        "\n",
        "embed_model = Model([word_input], word_vec)\n",
        "\n",
        "embed_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZZd_C7j4LzG",
        "outputId": "1af1490d-205a-4ee9-bac5-a2480f45118c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 14)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 14, 300)           315300    \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 300)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315300 (1.20 MB)\n",
            "Trainable params: 315300 (1.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embed_model.predict(x_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHlrEWvA4oPI",
        "outputId": "e35da07e-e6a2-4a7b-9e21-d14f66d32c20"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpLhUjLxnieu"
      },
      "source": [
        "# USE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "metadata": {
        "id": "AWGi7T6uNAIU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_USE(sentences, b_size) :\n",
        "    batch_size = b_size\n",
        "\n",
        "    for step in range(len(sentences) // batch_size) :\n",
        "        idx = step * batch_size\n",
        "        feat = embed(sentences[idx:idx + batch_size])\n",
        "        features = feat if step == 0 else np.concatenate((features, feat))\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "sczuiOkINES9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "sentences_USE = df['sentence_dl'].to_list()\n",
        "\n",
        "features = feature_USE(sentences_USE, batch_size)"
      ],
      "metadata": {
        "id": "7omd0jboNgUT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "id": "T-hdtCitOB4Z",
        "outputId": "bd18816a-56f2-42d2-a064-6c323c5bcabf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}