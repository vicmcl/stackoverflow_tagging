{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(\"data\")\n",
    "df = pd.read_json(dirpath / \"questions.json\").T\n",
    "df.index = [int(i.timestamp()) for i in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70730831</th>\n",
       "      <td>What&amp;#39;s the mathematical reason behind Pyth...</td>\n",
       "      <td>[python, c++, python-3.x, rounding, integer-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70793490</th>\n",
       "      <td>How do I calculate square root in Python?</td>\n",
       "      <td>[python, math, sqrt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70837397</th>\n",
       "      <td>Good alternative to Pandas .append() method, n...</td>\n",
       "      <td>[python, pandas, dataframe, data-wrangling, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70851048</th>\n",
       "      <td>Does it make sense to use Conda + Poetry?</td>\n",
       "      <td>[python, machine-learning, package, conda, pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70882092</th>\n",
       "      <td>Can we make 1 == 2 true?</td>\n",
       "      <td>[python, cpython, python-internals]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sentence  \\\n",
       "70730831  What&#39;s the mathematical reason behind Pyth...   \n",
       "70793490          How do I calculate square root in Python?   \n",
       "70837397  Good alternative to Pandas .append() method, n...   \n",
       "70851048          Does it make sense to use Conda + Poetry?   \n",
       "70882092                           Can we make 1 == 2 true?   \n",
       "\n",
       "                                                       tags  \n",
       "70730831  [python, c++, python-3.x, rounding, integer-di...  \n",
       "70793490                               [python, math, sqrt]  \n",
       "70837397  [python, pandas, dataframe, data-wrangling, da...  \n",
       "70851048  [python, machine-learning, package, conda, pyt...  \n",
       "70882092                [python, cpython, python-internals]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    return re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "\n",
    "def preprocessing(\n",
    "        text: str, \n",
    "        *,\n",
    "        pos: list[str] = [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"],\n",
    "        kind: str = \"bow\", # \"bow\" or \"dl\"\n",
    "        lemma: bool = False,\n",
    "        package: str = \"en_core_web_sm\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Preprocess a text by converting it to lower case, filtering alphanumeric characters and postags, and lemmatizing the tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): the string to be preprocessed\n",
    "        pos (list[str], optional): the postags to keep in the text. Defaults to [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"].\n",
    "        kind (str, optional): the kind of preprocessing, either \"bow\" (bag-of-words) or \"dl\" (deep learning). Defaults to \"bow\".\n",
    "        package (str, optional): the spaCy package to import for NLP. Defaults to \"en_core_web_sm\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: incompatible values for lemma and kind.\n",
    "        ValueError: unknown kind argument.\n",
    "\n",
    "    Returns:\n",
    "        str: the preprocessed version of the input text.\n",
    "    \"\"\"\n",
    "    # Manage incorrect arguments\n",
    "    if kind == \"dl\" and lemma: \n",
    "        raise ValueError('Incompatible values for lemma and kind.')\n",
    "    if kind not in [\"bow\", \"dl\"]:\n",
    "        raise ValueError(\"Unknown argument:\", kind)\n",
    "    \n",
    "    # Load the spacy package\n",
    "    nlp = spacy.load(package, disable=[\"parser\", \"ner\"])\n",
    "\n",
    "    # For deep learning, only remove the non-alphanumeric characters\n",
    "    if kind == \"dl\": \n",
    "        return clean_text(text.lower()).replace(\"  \", \" \").strip()\n",
    "\n",
    "    # For bag of words, remove the stop words and lemmatize if indicated\n",
    "    else:\n",
    "        output_text = \" \".join([\n",
    "            eval(\"token.\" + (\"lemma_\" if lemma else \"text\")) \n",
    "            for token in nlp(text.lower()) if token.pos_ in pos\n",
    "        ])\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_bow'] = df['sentence'].apply(lambda x : preprocessing(x))\n",
    "df['sentence_bow_lem'] = df['sentence'].apply(lambda x : preprocessing(x, lemma=True))\n",
    "df['sentence_dl'] = df['sentence'].apply(lambda x : preprocessing(x, kind=\"dl\"))\n",
    "\n",
    "df['length_bow'] = df['sentence_bow'].apply(lambda x : len(x.split()))\n",
    "df['length_dl'] = df['sentence_dl'].apply(lambda x : len(x.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
